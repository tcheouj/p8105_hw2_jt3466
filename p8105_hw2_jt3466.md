p8105_hw2_jt3466
================
Johnstone Tcheou
2024-09-24

# Question 1

This code reads in the NYC Transit Subway data, cleans the variable
names, and retains only the needed variables - `line`, `station_name`,
`station_latitude`, `station_longitude`, `route1:11`, `entry`,
`vending`, `entrance_type`, and `ada`. In order to pivot the data to a
longer format, all route variables need to be the same variable type, so
they are converted to character type. Afterwards, all rows with `NA` in
in subway lines are dropped, since not all stations have 11 routes. The
`entry` variable is then converted from character to logical type.
`vending` is also converted from character to logical for a later
question.

``` r
subway <- read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names() |>
  select(
    station_name, 
    division, 
    station_latitude, 
    station_longitude, 
    route1:route11, 
    entry, 
    vending, 
    entrance_type, 
    ada
  ) |>
  mutate(
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
  ) |>
  pivot_longer(
    cols = route1:route11, 
    names_to = "route",
    names_prefix = "route",
    values_to = "subway_line"
  ) |> 
  drop_na(subway_line) |>
  mutate(
    entry = case_match(
      entry, 
      "YES" ~ TRUE,
      "NO" ~ FALSE
    ), 
    vending = case_match(
      vending, 
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## How many distinct stations are there?

There are 356 distinct stations.

## How many stations are ADA compliant?

1616 stations are ADA compliant.

## What proportion of station entrances/exits without vending allow entrance?

Of the 447 stations without vending, 31.0961969% of them allow entrance.

## How many distinct stations serve the A train?

56 distinct stations serve the A train.

## Of the stations that serve the A train, how many are ADA compliant?

Of the 56 stations that serve the A train, 16 stations are ADA
compliant.

# Question 2

This code chunk imports the corresponding cell ranges and sheets for the
3 robots, `mr_trash`, `prof_trash`, and `gwynnda`. All dataframes are
read in with `read_excel`, had names cleaned using `clean_names`. A
variable, `robot`, was created for all dataframes to clearly show which
rows belong to which robot. In order to bind rows, the `year` variable
from the `mr_trash` dataframe needed to be explicitly coerced to
`double` type to match the other `year` variables from the other
dataframes.

``` r
mr_trash <- read_excel("data/202309 Trash Wheel Collection Data.xlsx", range = "A2:N586", sheet = "Mr. Trash Wheel") |>
  janitor::clean_names() |>
  mutate(
    sports_balls = as.integer(round(sports_balls, digits = 0)),
    year = as.double(year),
    robot = "Mr. Trash Wheel"
  )

prof_trash <- read_excel("data/202309 Trash Wheel Collection Data.xlsx", range = "A2:M108", sheet = "Professor Trash Wheel") |>
  janitor::clean_names() |>
  mutate(
    robot = "Professor Trash Wheel"
  )

gwynnda <- read_excel("data/202309 Trash Wheel Collection Data.xlsx", range = "A2:L157", sheet = "Gwynnda Trash Wheel") |>
  janitor::clean_names() |>
  mutate(
    robot = "Gwynnda"
  )

trash_wheels <- bind_rows(mr_trash, prof_trash, gwynnda)

summary(trash_wheels)
```

    ##     dumpster      month                year     
    ##  Min.   :  1   Length:845         Min.   :2014  
    ##  1st Qu.: 71   Class :character   1st Qu.:2017  
    ##  Median :162   Mode  :character   Median :2019  
    ##  Mean   :223                      Mean   :2019  
    ##  3rd Qu.:373                      3rd Qu.:2021  
    ##  Max.   :584                      Max.   :2023  
    ##                                                 
    ##       date                         weight_tons    volume_cubic_yards
    ##  Min.   :1900-01-20 00:00:00.00   Min.   :0.610   Min.   : 5.00     
    ##  1st Qu.:2017-06-21 00:00:00.00   1st Qu.:2.490   1st Qu.:15.00     
    ##  Median :2019-10-25 00:00:00.00   Median :3.070   Median :15.00     
    ##  Mean   :2019-06-08 04:53:06.75   Mean   :3.009   Mean   :15.13     
    ##  3rd Qu.:2021-11-04 00:00:00.00   3rd Qu.:3.540   3rd Qu.:15.00     
    ##  Max.   :2023-06-30 00:00:00.00   Max.   :5.620   Max.   :20.00     
    ##                                                                     
    ##  plastic_bottles  polystyrene    cigarette_butts  glass_bottles   
    ##  Min.   :   0    Min.   :    0   Min.   :     0   Min.   :  0.00  
    ##  1st Qu.:1000    1st Qu.:  280   1st Qu.:  3200   1st Qu.: 10.00  
    ##  Median :1980    Median :  950   Median :  5500   Median : 18.00  
    ##  Mean   :2296    Mean   : 1631   Mean   : 15592   Mean   : 20.89  
    ##  3rd Qu.:2900    3rd Qu.: 2400   3rd Qu.: 16000   3rd Qu.: 28.00  
    ##  Max.   :9830    Max.   :11528   Max.   :310000   Max.   :110.00  
    ##  NA's   :1       NA's   :1       NA's   :1        NA's   :156     
    ##   plastic_bags      wrappers      sports_balls   homes_powered  
    ##  Min.   :    0   Min.   :  180   Min.   : 0.00   Min.   : 0.00  
    ##  1st Qu.:  280   1st Qu.:  840   1st Qu.: 6.00   1st Qu.:37.83  
    ##  Median :  680   Median : 1380   Median :11.00   Median :49.50  
    ##  Mean   : 1082   Mean   : 2330   Mean   :13.17   Mean   :45.87  
    ##  3rd Qu.: 1400   3rd Qu.: 2635   3rd Qu.:18.25   3rd Qu.:57.50  
    ##  Max.   :13450   Max.   :20100   Max.   :56.00   Max.   :93.67  
    ##  NA's   :1       NA's   :118     NA's   :261     NA's   :2      
    ##     robot          
    ##  Length:845        
    ##  Class :character  
    ##  Mode  :character  
    ##                    
    ##                    
    ##                    
    ## 

The dataframe `trash_wheels` contains observations for all 3 robots -
Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. The number of
observations in the `trash_wheels` dataframe is 845. Key variables
include the `dumpster` number, the `month`, and `year` of the `date`,
the total weight in tons collected for that time point in `weight_tons`
(e.g. the average weight collected from all robots is 3.0094793 tons)
and the total volume of cubic yards of trash collected for that time
point in `volume_cubic_yards`. More detailed information on the amount
of types of garbage collected for each time point is offered for
`plastic_bottles` (e.g. the total plastic bottles collected across all
robots and all time points is 1.938223^{6}), `polystyrene`,
`cigarette_butts`, `glass_bottles`, `plastic_bags`, `wrappers`, and
`sports_balls`. The total amount of homes powered by the collected trash
is available in `homes_powered`. As mentioned earlier, the `robot`
variable designates what robot provided the data for that observation.

## What was the total weight of trash collected by Professor Trash Wheel?

Professor Trash Wheel collected 216.26 tons of trash.

## What was the total number of cigarettes butts collected by Gwynnda in June 2022?

Gwynnda collected 1.812^{4} cigarette butts in June 2022.

# Question 3

`results` and `bakes` are in long format already, but all the other
files need to be pivoted to long format by pivoting the `series`
variables to be their own observations. The `series` variable after
pivoting is a character type, so we need to convert it to double.
Lastly, all datasets are sorted by `series` first and then `episode`
afterwards. Additionally, the `results` file also has some headers and
the data doesn’t start until the 3rd row. Therefore, we need the
`skip=2` option. For later joining, the `baker_name` variable in
`bakers` is separated into a variable for the baker’s first and last
name, called `baker` and `baker_last_name`, respectively.

``` r
bakers <- read_csv("data/bakers.csv") |>
  janitor::clean_names() |>
  arrange(series) |>
  select(series, everything()) |>
  separate(baker_name, into = c("baker", "last_name"), sep = " ") |> 
  arrange(series, baker)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes <- read_csv("data/bakes.csv") |>
  janitor::clean_names() |>
  arrange(series, episode, baker)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results <- read_csv("data/results.csv", skip=2) |>
  janitor::clean_names() |>
  arrange(series, episode)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
summary(bakers)
```

    ##      series        baker            last_name           baker_age    
    ##  Min.   : 1.0   Length:120         Length:120         Min.   :17.00  
    ##  1st Qu.: 3.0   Class :character   Class :character   1st Qu.:28.75  
    ##  Median : 6.0   Mode  :character   Mode  :character   Median :34.00  
    ##  Mean   : 5.6                                         Mean   :37.39  
    ##  3rd Qu.: 8.0                                         3rd Qu.:45.00  
    ##  Max.   :10.0                                         Max.   :71.00  
    ##  baker_occupation     hometown        
    ##  Length:120         Length:120        
    ##  Class :character   Class :character  
    ##  Mode  :character   Mode  :character  
    ##                                       
    ##                                       
    ## 

``` r
summary(bakes)
```

    ##      series        episode          baker           signature_bake    
    ##  Min.   :1.00   Min.   : 1.000   Length:548         Length:548        
    ##  1st Qu.:3.00   1st Qu.: 2.000   Class :character   Class :character  
    ##  Median :5.00   Median : 4.000   Mode  :character   Mode  :character  
    ##  Mean   :4.81   Mean   : 4.192                                        
    ##  3rd Qu.:7.00   3rd Qu.: 6.000                                        
    ##  Max.   :8.00   Max.   :10.000                                        
    ##  show_stopper      
    ##  Length:548        
    ##  Class :character  
    ##  Mode  :character  
    ##                    
    ##                    
    ## 

``` r
summary(results)
```

    ##      series          episode         baker             technical     
    ##  Min.   : 1.000   Min.   : 1.00   Length:1136        Min.   : 1.000  
    ##  1st Qu.: 4.000   1st Qu.: 3.00   Class :character   1st Qu.: 2.000  
    ##  Median : 6.000   Median : 5.00   Mode  :character   Median : 4.000  
    ##  Mean   : 5.838   Mean   : 5.31                      Mean   : 4.843  
    ##  3rd Qu.: 8.000   3rd Qu.: 8.00                      3rd Qu.: 7.000  
    ##  Max.   :10.000   Max.   :10.00                      Max.   :13.000  
    ##                                                      NA's   :440     
    ##     result         
    ##  Length:1136       
    ##  Class :character  
    ##  Mode  :character  
    ##                    
    ##                    
    ##                    
    ## 

To check completeness of each dataset, `anti_joins` are conducted
between all the datasets.

These datasets can all be joined on `series` and `baker` (with `episode`
sometimes for extra assurance). `gb_bakers` is created by doing a left
join on `bakers` with `bakes` first by `series` and `baker` as composite
primary keys. Then, `gb_bakers` is combined with `results` on `series`,
`episode`, and `baker` via a left join. Drop the `baker`-prefix from
variables to simplify their names, like `baker_age`. Variables are first
ordered by `series` and `episode`, then the baker names, and their
`result`, followed by more `baker`-related information variables. **Rows
with `NA` in the `technical` or `result` variable for a given
`series`/`episode` combination indicate they were eliminated in the
prior episode, so these rows are ommitted.** The final dataset is then
saved as a .csv in the `data` subfolder, called `gb_bakers_data.csv`.

``` r
gb_bakers <- left_join(bakers, bakes, by = c("series", "baker")) |>
  left_join(results, by = c("series", "episode", "baker")) |>
  mutate(
    age = baker_age,
    occupation = baker_occupation
  ) |>
  select(
    series,
    episode,
    baker,
    last_name, 
    result,
    technical,
    everything()
  ) |>
  filter(!is.na(result))
 

write_csv(gb_bakers, "data/gb_bakers_data.csv")
```

From this final dataset, to get a table of star baker or winners from
seasons 5-10, `filter` the rows accordingly.

``` r
gb_bakers |>
  filter(
    series == 5:10 & (result == "WINNER" | result == "STAR BAKER")) |>
  knitr::kable(format = "html")
```

<table>
<thead>
<tr>
<th style="text-align:right;">
series
</th>
<th style="text-align:right;">
episode
</th>
<th style="text-align:left;">
baker
</th>
<th style="text-align:left;">
last_name
</th>
<th style="text-align:left;">
result
</th>
<th style="text-align:right;">
technical
</th>
<th style="text-align:right;">
baker_age
</th>
<th style="text-align:left;">
baker_occupation
</th>
<th style="text-align:left;">
hometown
</th>
<th style="text-align:left;">
signature_bake
</th>
<th style="text-align:left;">
show_stopper
</th>
<th style="text-align:right;">
age
</th>
<th style="text-align:left;">
occupation
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
Richard
</td>
<td style="text-align:left;">
Burr
</td>
<td style="text-align:left;">
STAR BAKER
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
38
</td>
<td style="text-align:left;">
Builder
</td>
<td style="text-align:left;">
Mill Hill, London
</td>
<td style="text-align:left;">
Rosemary Seeded Crackers
</td>
<td style="text-align:left;">
Pirates!
</td>
<td style="text-align:right;">
38
</td>
<td style="text-align:left;">
Builder
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:left;">
Richard
</td>
<td style="text-align:left;">
Burr
</td>
<td style="text-align:left;">
STAR BAKER
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
38
</td>
<td style="text-align:left;">
Builder
</td>
<td style="text-align:left;">
Mill Hill, London
</td>
<td style="text-align:left;">
Fruit Swedish Tea Ring
</td>
<td style="text-align:left;">
Rhubarb and Custard and Toffee Apple Doughnuts
</td>
<td style="text-align:right;">
38
</td>
<td style="text-align:left;">
Builder
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
Marie
</td>
<td style="text-align:left;">
Campbell
</td>
<td style="text-align:left;">
STAR BAKER
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
66
</td>
<td style="text-align:left;">
Retired
</td>
<td style="text-align:left;">
Auchterarder, Perthshire
</td>
<td style="text-align:left;">
Zingy Citrus Madeira Cake
</td>
<td style="text-align:left;">
A Walk in the Black Forest
</td>
<td style="text-align:right;">
66
</td>
<td style="text-align:left;">
Retired
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:left;">
Nadiya
</td>
<td style="text-align:left;">
Hussain
</td>
<td style="text-align:left;">
WINNER
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Full-time mother
</td>
<td style="text-align:left;">
Leeds / Luton
</td>
<td style="text-align:left;">
Cardamom and Almond Buns & Nutmeg and Sour Cherry Fingers
</td>
<td style="text-align:left;">
My Big Fat British Wedding Cake
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Full-time mother
</td>
</tr>
<tr>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:left;">
Andrew
</td>
<td style="text-align:left;">
Smyth
</td>
<td style="text-align:left;">
STAR BAKER
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Aerospace engineer
</td>
<td style="text-align:left;">
Derby / Holywood, County Down
</td>
<td style="text-align:left;">
Cheesy Elephant Ears and Herby Treble Clefs
</td>
<td style="text-align:left;">
Philharmonic Fondants
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Aerospace engineer
</td>
</tr>
<tr>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:left;">
Tom
</td>
<td style="text-align:left;">
Gilliford
</td>
<td style="text-align:left;">
STAR BAKER
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:left;">
Project engagement manager
</td>
<td style="text-align:left;">
Rochdale
</td>
<td style="text-align:left;">
Blood Orange Halloween Pumpkin Pie
</td>
<td style="text-align:left;">
Floral Tea Cake
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:left;">
Project engagement manager
</td>
</tr>
<tr>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
Julia
</td>
<td style="text-align:left;">
Chernogorova
</td>
<td style="text-align:left;">
STAR BAKER
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
Aviation Broker
</td>
<td style="text-align:left;">
Crawley, West Sussex
</td>
<td style="text-align:left;">
Earl Grey Dried Fruit Teacakes
</td>
<td style="text-align:left;">
‘The Snail Under a Mushroom’ Bread Sculpture
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
Aviation Broker
</td>
</tr>
<tr>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
Steven
</td>
<td style="text-align:left;">
Carter-Bailey
</td>
<td style="text-align:left;">
STAR BAKER
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
34
</td>
<td style="text-align:left;">
Marketer
</td>
<td style="text-align:left;">
Watford, Hertfordshire
</td>
<td style="text-align:left;">
Bonfire Night Cake
</td>
<td style="text-align:left;">
‘A Baker’s Lunch’ Cake
</td>
<td style="text-align:right;">
34
</td>
<td style="text-align:left;">
Marketer
</td>
</tr>
<tr>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;">
Steven
</td>
<td style="text-align:left;">
Carter-Bailey
</td>
<td style="text-align:left;">
STAR BAKER
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
34
</td>
<td style="text-align:left;">
Marketer
</td>
<td style="text-align:left;">
Watford, Hertfordshire
</td>
<td style="text-align:left;">
Italian Style Cannoli
</td>
<td style="text-align:left;">
‘Sicilian-style’ Sfogliatelle
</td>
<td style="text-align:right;">
34
</td>
<td style="text-align:left;">
Marketer
</td>
</tr>
</tbody>
</table>

``` r
viewers <- read_csv("data/viewers.csv") |>
  janitor::clean_names() |>
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    names_prefix = "series_",
    values_to = "viewers"
  ) |>
  mutate( 
    series = as.double(series) 
  ) |>
  select(
    series, episode, everything()
  ) |>
  arrange(series, episode)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
